/data/vision/torralba/selfmanaged/torralba/scratch/apprisco
My Job ID is 1028897
The time is Tue May  6 08:27:29 PM EDT 2025
This job is running on torralba-3090-1.csail.mit.edu
/data/vision/torralba/selfmanaged/torralba/scratch/apprisco
W0506 20:28:03.902000 236174 site-packages/torch/distributed/run.py:792]
W0506 20:28:03.902000 236174 site-packages/torch/distributed/run.py:792] *****************************************
W0506 20:28:03.902000 236174 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W0506 20:28:03.902000 236174 site-packages/torch/distributed/run.py:792] *****************************************
Running on 7 GPUs
  GPU 0: NVIDIA GeForce RTX 3090
  GPU 1: NVIDIA GeForce RTX 3090
  GPU 2: NVIDIA GeForce RTX 3090
  GPU 3: NVIDIA GeForce RTX 3090
  GPU 4: NVIDIA GeForce RTX 3090
  GPU 5: NVIDIA GeForce RTX 3090
  GPU 6: NVIDIA GeForce RTX 3090
Epoch 1/5: 100%|██████████| 1811/1811 [36:17<00:00,  1.20s/it, avg_loss=0.17]
Epoch 1 complete — avg loss: 0.1696
Epoch 2/5: 100%|██████████| 1811/1811 [36:03<00:00,  1.19s/it, avg_loss=0.17]
Epoch 2 complete — avg loss: 0.1702
Epoch 3/5: 100%|██████████| 1811/1811 [36:08<00:00,  1.20s/it, avg_loss=0.168]
Epoch 3 complete — avg loss: 0.1677
Epoch 4/5: 100%|██████████| 1811/1811 [36:05<00:00,  1.20s/it, avg_loss=0.169]
Epoch 4 complete — avg loss: 0.1687
Epoch 5/5: 100%|██████████| 1811/1811 [36:04<00:00,  1.20s/it, avg_loss=0.168]
Epoch 5 complete — avg loss: 0.1682
W0506 23:32:27.450000 332123 site-packages/torch/distributed/run.py:792]
W0506 23:32:27.450000 332123 site-packages/torch/distributed/run.py:792] *****************************************
W0506 23:32:27.450000 332123 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W0506 23:32:27.450000 332123 site-packages/torch/distributed/run.py:792] *****************************************
Running on 7 GPUs
  GPU 0: NVIDIA GeForce RTX 3090
  GPU 1: NVIDIA GeForce RTX 3090
  GPU 2: NVIDIA GeForce RTX 3090
  GPU 3: NVIDIA GeForce RTX 3090
  GPU 4: NVIDIA GeForce RTX 3090
  GPU 5: NVIDIA GeForce RTX 3090
  GPU 6: NVIDIA GeForce RTX 3090
Epoch 1/5: 100%|██████████| 1830/1830 [36:32<00:00,  1.20s/it, avg_loss=0.165]
Epoch 1 complete — avg loss: 0.1649
Epoch 2/5: 100%|██████████| 1830/1830 [36:27<00:00,  1.20s/it, avg_loss=0.167]
Epoch 2 complete — avg loss: 0.1671
Epoch 3/5: 100%|██████████| 1830/1830 [36:25<00:00,  1.19s/it, avg_loss=0.164]
Epoch 3 complete — avg loss: 0.1636
Epoch 4/5: 100%|██████████| 1830/1830 [36:25<00:00,  1.19s/it, avg_loss=0.163]
Epoch 4 complete — avg loss: 0.1634
Epoch 5/5: 100%|██████████| 1830/1830 [36:25<00:00,  1.19s/it, avg_loss=0.164]
Epoch 5 complete — avg loss: 0.1644
W0507 02:37:24.901000 433012 site-packages/torch/distributed/run.py:792]
W0507 02:37:24.901000 433012 site-packages/torch/distributed/run.py:792] *****************************************
W0507 02:37:24.901000 433012 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W0507 02:37:24.901000 433012 site-packages/torch/distributed/run.py:792] *****************************************
Running on 7 GPUs
  GPU 0: NVIDIA GeForce RTX 3090
  GPU 1: NVIDIA GeForce RTX 3090
  GPU 2: NVIDIA GeForce RTX 3090
  GPU 3: NVIDIA GeForce RTX 3090
  GPU 4: NVIDIA GeForce RTX 3090
  GPU 5: NVIDIA GeForce RTX 3090
  GPU 6: NVIDIA GeForce RTX 3090
Epoch 1/5: 100%|██████████| 1751/1751 [34:53<00:00,  1.20s/it, avg_loss=0.166]
Epoch 1 complete — avg loss: 0.1663
Epoch 2/5: 100%|██████████| 1751/1751 [34:52<00:00,  1.19s/it, avg_loss=0.166]
Epoch 2 complete — avg loss: 0.1663
Epoch 3/5: 100%|██████████| 1751/1751 [34:51<00:00,  1.19s/it, avg_loss=0.164]
Epoch 3 complete — avg loss: 0.1641
Epoch 4/5: 100%|██████████| 1751/1751 [34:52<00:00,  1.19s/it, avg_loss=0.165]
Epoch 4 complete — avg loss: 0.1645
Epoch 5/5: 100%|██████████| 1751/1751 [34:50<00:00,  1.19s/it, avg_loss=0.165]
Epoch 5 complete — avg loss: 0.1647
W0507 05:33:33.449000 538879 site-packages/torch/distributed/run.py:792]
W0507 05:33:33.449000 538879 site-packages/torch/distributed/run.py:792] *****************************************
W0507 05:33:33.449000 538879 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
W0507 05:33:33.449000 538879 site-packages/torch/distributed/run.py:792] *****************************************
Running on 7 GPUs
  GPU 0: NVIDIA GeForce RTX 3090
  GPU 1: NVIDIA GeForce RTX 3090
  GPU 2: NVIDIA GeForce RTX 3090
  GPU 3: NVIDIA GeForce RTX 3090
  GPU 4: NVIDIA GeForce RTX 3090
  GPU 5: NVIDIA GeForce RTX 3090
  GPU 6: NVIDIA GeForce RTX 3090
Epoch 1/5: 100%|██████████| 1675/1675 [33:24<00:00,  1.20s/it, avg_loss=0.167]
Epoch 1 complete — avg loss: 0.1668
Epoch 2/5: 100%|██████████| 1675/1675 [33:21<00:00,  1.20s/it, avg_loss=0.165]
Epoch 2 complete — avg loss: 0.1652
Epoch 3/5: 100%|██████████| 1675/1675 [33:19<00:00,  1.19s/it, avg_loss=0.165]
Epoch 3 complete — avg loss: 0.1653
Epoch 4/5: 100%|██████████| 1675/1675 [33:20<00:00,  1.19s/it, avg_loss=0.166]
Epoch 4 complete — avg loss: 0.1658
Epoch 5/5: 100%|██████████| 1675/1675 [33:20<00:00,  1.19s/it, avg_loss=0.165]
Epoch 5 complete — avg loss: 0.1652
slurm_load_jobs error: Invalid job id specified
Job 1028897 completed. Stopping log tail.
